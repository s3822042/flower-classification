{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "616e87907fb14d828047e4d1862d323f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "309ae93afd4e47eea0bbed99f137feaa",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 964,
    "execution_start": 1672922786932,
    "source_hash": "c9f2b450",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# specifically for manipulating zipped images and getting numpy arrays of pixel values of images.\n",
    "import cv2     \n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#image reader\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skew Correction\n",
    "While scanning or taking a picture of any document, it is possible that the scanned or captured image might be slightly skewed sometimes. For the better performance of the OCR, it is good to determine the skewness in image and correct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskew(image):\n",
    "    co_ords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(co_ords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC,\n",
    "    borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise Removal\n",
    "This step removes the small dots/patches which have high intensity compared to the rest of the image for smoothening of the image. OpenCV’s fast Nl Means Denoising Coloured function can do that easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(image):\n",
    "    return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gray Scale image\n",
    "This process converts an image from other color spaces to shades of Gray. The colour varies between complete black and complete white. OpenCV’s cvtColor() function perform this task very easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thresholding or Binarization\n",
    "This step converts any colored image into a binary image that contains only two colors black and white. It is done by fixing a threshold (normally half of the pixel range 0-255, i.e., 127). The pixel value having greater than the threshold is converted into a white pixel else into a black pixel. To determine the threshold value according to the image Otsu’s Binarization and Adaptive Binarization can be a better choice. In OpenCV, this can be done as given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY +\n",
    "    cv2.THRESH_OTSU) [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8402cea9e1514de78c855730d54e7a43",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Detect corrupt image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is crucial to detect corrupted images, as they can negatively impact the performance of a machine learning model or computer vision system. Images that have been corrupted may contain noise, artifacts, or other anomalies that can lead to misclassifications or output errors. Improve the accuracy and dependability of a model or system by detecting and removing these images from the dataset. In addition, corrupted images can cause biases in the model or system, which can lead to erroneous results or unjust decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7b7cb2c75fca40999fe0cad4f0195c79",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8943,
    "execution_start": 1672922788090,
    "source_hash": "b424dde3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "corrupted_image = list()\n",
    "dataset_path = \"Flowers/Flowers\"\n",
    "accu = 0\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for name in dirs:\n",
    "        print(os.path.join(root, name))\n",
    "        for image_file in Path(os.path.join(root, name)).glob('*.jpg'):\n",
    "          accu = accu + 1\n",
    "          try :\n",
    "              image = Image.open(image_file)\n",
    "              image.show()\n",
    "              img = imageio.imread(image_file)\n",
    "              image.show()\n",
    "              img = deskew(img)\n",
    "              image.show()\n",
    "              img = remove_noise(img)\n",
    "              image.show()\n",
    "              img = get_grayscale(img)\n",
    "              image.show()\n",
    "              norm_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "              img = cv2.normalize(img, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "              image.show()\n",
    "            #   print(f'read {image_file}')\n",
    "          except :\n",
    "              print(f'Cannot read image {image_file}')\n",
    "              corrupted_image.append(image_file)\n",
    "print(\"Total number of images : \", accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c39491b4dc644946b3c0da8ece483dee",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 43,
    "execution_start": 1672922797036,
    "scrolled": true,
    "source_hash": "7c73fbbc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(corrupted_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization\n",
    "This process changes the range of pixel intensity values. The purpose of performing normalization is to bring image to range that is normal to sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "258e7da2189b45738169d35a260bbfc7",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Image duplication detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate image detection is essential for multiple reasons:\n",
    "\n",
    "* <b>Reducing storage</b>: Storing duplicate images wastes storage space, and detecting and removing them can help reduce storage costs.\n",
    "\n",
    "* <b>Improving efficiency</b>: Processing or analyzing duplicate images is inefficient and time-consuming. Removing duplicates can improve processing and analysis efficiency.\n",
    "\n",
    "* <b>Enhancing accuracy</b>: Duplicate images can bias the results of image-based analysis, such as object detection or image classification. Removing duplicates can improve the accuracy of these analyses.\n",
    "\n",
    "* <b>Maintaining data integrity</b>: Duplicates can lead to confusion and inconsistency in data, especially when dealing with large image datasets. Removing duplicates helps to maintain data integrity and consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9d279441058a4f63995752f120a7746c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 161303,
    "execution_start": 1672922797325,
    "source_hash": "a616d0bf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import imagehash\n",
    "import glob\n",
    "\n",
    "# Define a function to compute the hash of an image file\n",
    "def compute_hash(filepath):\n",
    "    with Image.open(filepath) as img:\n",
    "        return str(imagehash.phash(img))\n",
    "\n",
    "# Define a function to find and remove duplicated images\n",
    "def remove_duplicates(rootdir):\n",
    "    hashes = {}\n",
    "    duplicated = []\n",
    "    rootdir = glob.glob(rootdir)\n",
    "    for folder in rootdir:\n",
    "        print()\n",
    "        print(folder)\n",
    "        for image_dir in glob.glob(folder+'/*.jpg'):\n",
    "            # Compute the hash of the image file\n",
    "            file_hash = compute_hash(image_dir)\n",
    "            # Check if this hash has already been seen\n",
    "            file=os.path.basename(image_dir).split('/')[-1]\n",
    "            if file_hash in hashes:\n",
    "                # This file is a duplicate, so remove it\n",
    "                os.remove(image_dir)\n",
    "                print(f'Removed duplicate file: {file}')\n",
    "                duplicated.append(file)\n",
    "            else:\n",
    "                # This file is not a duplicate, so remember its hash\n",
    "                hashes[file_hash] = file\n",
    "        print(r'Duplicated image in ',folder,' :',len(duplicated))\n",
    "\n",
    "# Usage: specify the root directory to search for duplicates\n",
    "remove_duplicates('Flowers/Flowers/*')"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "104b4bb7d35d4086b1caf300c3bd47f4",
  "deepnote_persisted_session": {
   "createdAt": "2023-01-05T13:31:34.092Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
