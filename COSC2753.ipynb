{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# GROUP ASSIGNMENT [COSC2753]\n",
    "\n",
    "**Members**:\n",
    "- Vo Thanh Luan â€“ s3822042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocess image data\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import imageio.v2 as imageio\n",
    "import imagehash\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# Image reprocessing and image extraction\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import datetime\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# I. Problem statement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem at hand is to develop a machine learning model for an online flower shop that enables customers to search for flowers based on images rather than textual input. The existing approach in most online flower stores requires customers to manually enter the name of the flowers they are looking for, which may not always be accurate or convenient. To enhance the search experience and provide more accurate results, our goal is to create an image-based search tool. This notebook will provide the solution for customers to upload photographs of the flowers they desire, and the system will perform an image search to generate a list of flowers that closely resemble the user-provided image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T00:05:13.019861Z",
     "start_time": "2023-05-03T00:05:11.508682Z"
    },
    "collapsed": false
   },
   "source": [
    "To achieve this, the model needs to address two main tasks:\n",
    "\n",
    "- Task 1: Flower Classification\n",
    "The model should be trained to classify images according to different flower types. The dataset contains eight types of flowers: Baby, Calimero, Chrysanthemum, Hydrangeas, Lisianthus, Pingpong, Rosy, and Tana. The objective is to develop a classification algorithm that accurately identifies the flower type based on the input image.\n",
    "\n",
    "- Task 2: Similar Flower Recommendations\n",
    "Once the model is capable of classifying flower images, it should further be trained to recommend similar flower images from the dataset. Given an input flower image from a user, the model should generate a list of ten flower images that closely resemble the input image. This will provide customers with relevant and visually similar options for their desired flowers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Data retrieving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T00:40:26.383950Z",
     "start_time": "2023-05-03T00:40:26.369540Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flower_dataset_directory = \"data/Flowers/\"\n",
    "flower_category_foldername = os.listdir(flower_dataset_directory)\n",
    "print(flower_category_foldername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T00:13:33.909654Z",
     "start_time": "2023-05-03T00:13:33.895596Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link = []\n",
    "for label in flower_category_foldername:\n",
    "    path = os.path.join(flower_dataset_directory, label) # combine path and labels\n",
    "    link.append(path) # append in link\n",
    "print(link)\n",
    "\n",
    "for i in range(len(link)):\n",
    "    new = os.listdir(link[i])\n",
    "    i+=1\n",
    "    print(f\"length : cd {len(new)}\") # each folder total image count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explanatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Color channel distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_color_distribution(main_folder):\n",
    "    # Get a list of all sub-folders in the main folder\n",
    "    sub_folders = [f.path for f in os.scandir(main_folder) if f.is_dir()]\n",
    "\n",
    "    # Create a figure with 8 sub-plots\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(16,8))\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    # Loop through each sub-folder and plot the color channel data for each image\n",
    "    for i in range(len(sub_folders)):\n",
    "        # Get the name of the sub-folder\n",
    "        sub_folder_name = os.path.basename(sub_folders[i])\n",
    "\n",
    "        # Get a list of all image file names in the sub-folder\n",
    "        file_names = os.listdir(sub_folders[i])\n",
    "        file_names = [f for f in file_names if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "\n",
    "        # Initialize an array to store the color channel data\n",
    "        channel_data = np.zeros((256, 3))\n",
    "\n",
    "        # Loop through each image and accumulate the color channel data\n",
    "        for j in range(len(file_names)):\n",
    "            # Load the image file\n",
    "            img_path = os.path.join(sub_folders[i], file_names[j])\n",
    "            img = plt.imread(img_path)\n",
    "\n",
    "            # Accumulate the color channel data\n",
    "            for k in range(3):\n",
    "                channel_data[:, k] += np.histogram(img[:, :, k], bins=256, range=(0, 256))[0]\n",
    "\n",
    "        # Normalize the color channel data to percentages\n",
    "        channel_data /= np.sum(channel_data, axis=0)\n",
    "        channel_data *= 100\n",
    "\n",
    "        # Define the colors and labels for the line plots\n",
    "        colors = ['red', 'green', 'blue']\n",
    "        labels = ['Red', 'Green', 'Blue']\n",
    "\n",
    "        # Plot the percentage of each color channel for the category\n",
    "        for k in range(3):\n",
    "            axs[i].plot(range(256), channel_data[:, k], label=labels[k], color=colors[k], linewidth=1)\n",
    "\n",
    "        # Set the title and legend for the sub-plot\n",
    "        axs[i].set_title(sub_folder_name)\n",
    "        axs[i].legend()\n",
    "\n",
    "    # Set the plot title and axis labels\n",
    "    fig.suptitle(\"Color channel distribution (percentage) of flower images\", fontsize=20)\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xlabel(\"Pixel value\")\n",
    "        ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_color_distribution(flower_dataset_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Image size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_size_distribution(img_dir):\n",
    "    categories = os.listdir(img_dir)\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(20,10))\n",
    "    fig.suptitle('Image Size Distribution by Category')\n",
    "    for i, category in enumerate(categories):\n",
    "        size_list = []\n",
    "        for filename in os.listdir(os.path.join(img_dir, category)):\n",
    "            img_path = os.path.join(img_dir, category, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            size = os.path.getsize(img_path)\n",
    "            size_list.append(size)\n",
    "\n",
    "        ax = axs[i//4, i%4]\n",
    "        ax.hist(size_list, bins=50)\n",
    "        ax.set_title(category)\n",
    "        ax.set_xlabel('Image Size (Bytes)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size_distribution(flower_dataset_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Flower category distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_distribution(main_dir):\n",
    "    categories = os.listdir(main_dir)\n",
    "    category_counts = [len(os.listdir(os.path.join(main_dir, cat))) for cat in categories]\n",
    "    plt.bar(categories, category_counts)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('Categories')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title('Flower Category Distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_category_distribution(flower_dataset_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE=[]\n",
    "LABEL=[]\n",
    "IMG_SIZE=200\n",
    "\n",
    "def assign_label(img,flower_category):\n",
    "    return flower_category\n",
    "\n",
    "def make_train_data(flower_category,DIR):\n",
    "    for img in tqdm(os.listdir(DIR)):\n",
    "        label=assign_label(img,flower_category)\n",
    "        path = os.path.join(DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "        IMAGE.append(np.array(img))\n",
    "        LABEL.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOWER_DIR = []\n",
    "\n",
    "for category in flower_category_foldername:\n",
    "    flower_dir = f\"data/Flowers/{category}\"\n",
    "    FLOWER_DIR.append(flower_dir)\n",
    "    make_train_data(category, flower_dir)\n",
    "print(len(IMAGE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path=\"data/Flowers/Babi/babi_1.jpg\"\n",
    "destination_folder = r\"Flowers_Cleaned/Flowers\"\n",
    "\n",
    "#read image\n",
    "img = mpimg.imread(sample_path)\n",
    "\n",
    "#show image\n",
    "plt.imshow(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(image):\n",
    "    return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_before_after(img,img_after,title_after):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Original\")\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(img_after)\n",
    "    plt.title(title_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_before_after(img,remove_noise(img),\"After Noise Removal\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process changes the range of pixel intensity values. The purpose of performing normalization is to bring image to range that is normal to sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(img):\n",
    "    norm_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "    return cv2.normalize(img, norm_img, 0, 255, cv2.NORM_MINMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_before_after(img,normalization(img),\"After Normalization\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Check image filetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image_extensions(input_dir, allowed_extensions):\n",
    "    # Initialize a dictionary to count the number of files of each type\n",
    "    file_count = {extension: 0 for extension in allowed_extensions}\n",
    "    # Loop over each flower category\n",
    "    for category in os.listdir(input_dir):\n",
    "        # Get the path to the category directory\n",
    "        category_dir = os.path.join(input_dir, category)\n",
    "        # Loop over each image file in the category directory\n",
    "        for filename in os.listdir(category_dir):\n",
    "            # Get the file extension of the image file\n",
    "            extension = os.path.splitext(filename)[-1]\n",
    "            # Check if the extension is allowed\n",
    "            if extension in allowed_extensions:\n",
    "                # Increment the file count for the extension\n",
    "                file_count[extension] += 1\n",
    "            else:\n",
    "                print(f\"Error: {filename} in {category} has invalid extension {extension}\")\n",
    "    # Calculate the total number of files\n",
    "    total_files = sum(file_count.values())\n",
    "    # Print the percentage of each file type\n",
    "    for extension, count in file_count.items():\n",
    "        percentage = count / total_files * 100\n",
    "        print(f\"{extension}: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_extensions = {\".jpg\"}\n",
    "check_image_extensions(flower_dataset_directory, allowed_extensions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Detect corrupt image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is crucial to detect corrupted images, as they can negatively impact the performance of a machine learning model or computer vision system. Images that have been corrupted may contain noise, artifacts, or other anomalies that can lead to misclassifications or output errors. Improve the accuracy and dependability of a model or system by detecting and removing these images from the dataset. In addition, corrupted images can cause biases in the model or system, which can lead to erroneous results or unjust decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_folder():\n",
    "    shutil.copytree(flower_dataset_directory, destination_folder)\n",
    "    print('Copied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_image = list()\n",
    "accu = 0\n",
    "\n",
    "for root, dirs, files in os.walk(flower_dataset_directory):\n",
    "    for name in dirs:\n",
    "        print(os.path.join(root, name))\n",
    "        for image_file in Path(os.path.join(root, name)).glob('*.jpg'):\n",
    "          accu = accu + 1\n",
    "          try :\n",
    "              image = imageio.imread(image_file)\n",
    "            #   print(f'read {image_file}')\n",
    "          except :\n",
    "              print(f'Cannot read image {image_file}')\n",
    "              corrupted_image.add(image_file)\n",
    "print(\"Total number of images : \", accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corrupted_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Image duplication detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate image detection is essential for multiple reasons:\n",
    "\n",
    "1. Reducing storage: Storing duplicate images wastes storage space, and detecting and removing them can help reduce storage costs.\n",
    "\n",
    "2. Improving efficiency: Processing or analyzing duplicate images is inefficient and time-consuming. Removing duplicates can improve processing and analysis efficiency.\n",
    "\n",
    "3. Enhancing accuracy: Duplicate images can bias the results of image-based analysis, such as object detection or image classification. Removing duplicates can improve the accuracy of these analyses.\n",
    "\n",
    "4. Maintaining data integrity: Duplicates can lead to confusion and inconsistency in data, especially when dealing with large image datasets. Removing duplicates helps to maintain data integrity and consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dupes(img_name1, img_name2):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    imgplot = plt.imshow(Image.open(img_name1))\n",
    "    title_name1=os.path.basename(img_name1).split('/')[-1]\n",
    "    ax.set_title(title_name1)\n",
    "    \n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    imgplot = plt.imshow(Image.open(img_name2))\n",
    "    title_name2=os.path.basename(img_name2).split('/')[-1]\n",
    "    ax.set_title(title_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = {}\n",
    "duplicated = []   \n",
    "\n",
    "# Define a function to compute the hash of an image file\n",
    "def compute_hash(filepath):\n",
    "    with Image.open(filepath) as img:\n",
    "        return str(imagehash.phash(img))\n",
    "    \n",
    "# Define a function to find and remove duplicated images\n",
    "def check_duplicates(rootdir):\n",
    "    duplicated = []\n",
    "    rootdir = glob.glob(rootdir)\n",
    "    for folder in rootdir:\n",
    "        print()\n",
    "        print(folder)\n",
    "        for image_dir in glob.glob(folder+'/*.jpg'):\n",
    "            # Compute the hash of the image file\n",
    "            file_hash = compute_hash(image_dir)\n",
    "            # Check if this hash has already been seen\n",
    "            file=os.path.basename(image_dir).split('/')[-1]\n",
    "            if file_hash in hashes:\n",
    "                # if the image hash exists already, save the collision filenames\n",
    "                dupe_idx = hashes[file_hash]\n",
    "                duplicated.append((dupe_idx, image_dir))\n",
    "            else:\n",
    "                # This file is not a duplicate, so remember its hash\n",
    "                hashes[file_hash] = image_dir\n",
    "        print(r'Duplicated image in ',folder,' :',len(duplicated))\n",
    "    if len(duplicated)>0:\n",
    "        print(r'---- Examples of duplication ----')\n",
    "        show_dupes(duplicated[0][0], duplicated[0][1])\n",
    "        show_dupes(duplicated[1][0], duplicated[1][1])\n",
    "        show_dupes(duplicated[2][0], duplicated[2][1])\n",
    "\n",
    "# Define a function to find and remove duplicated images\n",
    "def remove_duplicates(rootdir):\n",
    "    rootdir = glob.glob(rootdir)\n",
    "    for folder in rootdir:\n",
    "        print()\n",
    "        print(folder)\n",
    "        for image_dir in glob.glob(folder+'/*.jpg'):\n",
    "            # Compute the hash of the image file\n",
    "            file_hash = compute_hash(image_dir)\n",
    "            # Check if this hash has already been seen\n",
    "            file=os.path.basename(image_dir).split('/')[-1]\n",
    "            if file_hash in hashes:\n",
    "                os.remove(image_dir)\n",
    "                print(f'Removed duplicate file: {file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_duplicates('Flowers_Cleaned/Flowers/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_duplicates('Flowers_Cleaned/Flowers/*')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Check image resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in IMAGE:\n",
    "    print(img.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check image outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "def calculate_image_features(img_path):\n",
    "    # Load the image and convert to grayscale\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the image's contrast and brightness\n",
    "    min_gray = gray.min()\n",
    "    max_gray = gray.max()\n",
    "    contrast = (max_gray - min_gray) / max_gray\n",
    "    brightness = gray.mean()\n",
    "    \n",
    "    # Return the image's features as a NumPy array\n",
    "    return np.array([contrast, brightness])\n",
    "\n",
    "def detect_outliers_in_category(category_path):\n",
    "    # Calculate the features for each image in the category\n",
    "    X = []\n",
    "    for file_name in os.listdir(category_path):\n",
    "        file_path = os.path.join(category_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            features = calculate_image_features(file_path)\n",
    "            X.append(features)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # Detect outliers using the LOF algorithm\n",
    "    clf = LocalOutlierFactor(n_neighbors=20)\n",
    "    y_pred = clf.fit_predict(X)\n",
    "    \n",
    "    # Plot the LOF scores for each image\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap='cool')\n",
    "    plt.colorbar()\n",
    "    plt.title(category_path)\n",
    "    plt.xlabel('Contrast')\n",
    "    plt.ylabel('Brightness')\n",
    "    plt.show()\n",
    "\n",
    "def detect_outliers_in_all_categories(root_path):\n",
    "    for category_name in os.listdir(root_path):\n",
    "        category_path = os.path.join(root_path, category_name)\n",
    "        if os.path.isdir(category_path):\n",
    "            detect_outliers_in_category(category_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_outliers_in_all_categories(flower_dataset_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Task 2: Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16 - A Deep Convolutional Neural Network Architecture for Image Recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VGG16 architecture, introduced by Karen Simonyan and Andrew Zisserman in 2014, has demonstrated remarkable performance in the field of image recognition. With its increased depth and improved representational power, VGG16 has become a popular choice for complex visual recognition tasks. This report provides an overview of the VGG16 model, highlighting its key characteristics, advantages, and disadvantages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Resnet50 For Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display a single image\n",
    "def display_image(path):\n",
    "    img = Image.open(path)\n",
    "    display(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Recommender using ResNet50 Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Recommender using VGG16 Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
