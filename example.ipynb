{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# set source and destination directories\n",
    "source_dir = './data/Flowers'\n",
    "dest_dir = './merge_images'\n",
    "\n",
    "# create destination directory if it doesn't exist\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir)\n",
    "\n",
    "# loop through subdirectories in source directory\n",
    "for subdir in os.listdir(source_dir):\n",
    "    subdir_path = os.path.join(source_dir, subdir)\n",
    "    # loop through image files in subdirectory\n",
    "    for file in os.listdir(subdir_path):\n",
    "        # get full path of source file\n",
    "        src_file = os.path.join(subdir_path, file)\n",
    "        # create destination file path\n",
    "        dest_file = os.path.join(dest_dir, file)\n",
    "        # copy file from source to destination\n",
    "        shutil.copy(src_file, dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map flower names to label numbers\n",
    "flower_labels = {'babi': 0, 'calimerio': 1, 'chrysanthemum': 2, 'hydrangeas': 3, \n",
    "                 'lisianthus': 4, 'pingpong': 5, 'rosy': 6, 'tana': 7}\n",
    "\n",
    "# Create an empty list to store the data rows for the CSV file\n",
    "data_rows = []\n",
    "\n",
    "# Loop over each flower folder\n",
    "for flower_folder in os.listdir(source_dir):\n",
    "    \n",
    "    # Get the label for this flower folder\n",
    "    label = flower_labels[flower_folder.lower()]\n",
    "    \n",
    "    # Loop over each image file in this flower folder\n",
    "    for file_name in os.listdir(os.path.join(source_dir, flower_folder)):\n",
    "        \n",
    "        # Create a new row for this image file\n",
    "        row = {'flower': file_name, 'label': label}\n",
    "        \n",
    "        # Add the row to the list of data rows\n",
    "        data_rows.append(row)\n",
    "\n",
    "# Write the data rows to a CSV file\n",
    "with open('flower_labels.csv', 'w') as f:\n",
    "    f.write('flower,label\\n')\n",
    "    for row in data_rows:\n",
    "        f.write('{},{:d}\\n'.format(row['flower'], row['label']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = Image.open(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, y_label)\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 2\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "my_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224,224)),\n",
    "])\n",
    "\n",
    "# Load Data\n",
    "dataset = FlowerDataset(\n",
    "    csv_file=\"metadata.csv\",\n",
    "    root_dir=dest_dir,\n",
    "    transform=my_transform,\n",
    ")\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [1, 1])\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models import vgg16\n",
    "vgg16_model = vgg16(weights=None)\n",
    "\n",
    "# final layer is not frozen\n",
    "vgg16_model.fc = nn.Linear(in_features=1024, out_features=num_classes)\n",
    "vgg16_model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg16_model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vtlua\\Downloads\\flower-classification\\myenv\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 0 is 6.868964672088623\n",
      "Cost at epoch 1 is 4.952603340148926\n",
      "Cost at epoch 2 is 0.0\n",
      "Cost at epoch 3 is 0.0\n",
      "Cost at epoch 4 is 0.0\n",
      "Cost at epoch 5 is 0.0\n",
      "Cost at epoch 6 is 0.0\n",
      "Cost at epoch 7 is 0.0\n",
      "Cost at epoch 8 is 0.0\n",
      "Cost at epoch 9 is 0.0\n",
      "Checking accuracy on Training Set\n",
      "Got 1 / 1 with accuracy 100.00\n",
      "Checking accuracy on Test Set\n",
      "Got 0 / 1 with accuracy 0.00\n"
     ]
    }
   ],
   "source": [
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # forward\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        scores = vgg16_model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward            \n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\n",
    "\n",
    "# Check accuracy on training\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(\n",
    "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
    "        )\n",
    "\n",
    "    model.train()\n",
    "\n",
    "\n",
    "print(\"Checking accuracy on Training Set\")\n",
    "check_accuracy(train_loader, vgg16_model)\n",
    "\n",
    "print(\"Checking accuracy on Test Set\")\n",
    "check_accuracy(test_loader, vgg16_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
