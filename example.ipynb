{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGGNet(\n",
    "    name: str,\n",
    "    architecture: typing.List[ typing.Union[int, str] ],\n",
    "    input_shape: typing.Tuple[int],\n",
    "    classes: int = 1000\n",
    ") -> tf.keras.Model:\n",
    "    X_input = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    X = make_conv_layer(X_input, architecture)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    X = make_dense_layer(X, 4096)\n",
    "    X = make_dense_layer(X, 4096)\n",
    "\n",
    "    # classification layer\n",
    "    X = tf.keras.layers.Dense(units = classes, activation = \"softmax\")(X)\n",
    "\n",
    "    model = tf.keras.Model(inputs = X_input, outputs = X, name = name)\n",
    "    return model\n",
    "\n",
    "def make_conv_layer(\n",
    "    X: tf.Tensor,\n",
    "    architecture: typing.List[ typing.Union[int, str] ],\n",
    "    activation: str = 'relu'\n",
    ") -> tf.Tensor:\n",
    "\n",
    "    for output in architecture:\n",
    "\n",
    "        if type(output) == int:\n",
    "            out_channels = output\n",
    "\n",
    "            X = tf.keras.layers.Conv2D(\n",
    "                filters = out_channels,\n",
    "                kernel_size = (3, 3),\n",
    "                strides = (1, 1),\n",
    "                padding = \"same\"\n",
    "            )(X)\n",
    "            X = tf.keras.layers.BatchNormalization()(X)\n",
    "            X = tf.keras.layers.Activation(activation)(X)\n",
    "        else:\n",
    "            X = tf.keras.layers.MaxPooling2D(\n",
    "                pool_size = (2, 2),\n",
    "                strides = (2, 2)\n",
    "            )(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def make_dense_layer(X: tf.Tensor, output_units: int, dropout = 0.5, activation = 'relu') -> tf.Tensor:\n",
    "    X = tf.keras.layers.Dense(units = output_units)(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation(activation)(X)\n",
    "    X = tf.keras.layers.Dropout(dropout)(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_types = {\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "vgg_model = VGGNet(name = \"VGGNet16\", architecture = VGG_types[\"VGG16\"], input_shape=(224, 224, 3), classes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGGNet16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 224, 224, 64)     256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 224, 224, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 112, 112, 128)    512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 112, 112, 128)    512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 56, 56, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 56, 56, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 56, 56, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 28, 28, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 28, 28, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 28, 28, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 4096)             16384     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 4096)             16384     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 32776     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,342,984\n",
      "Trainable params: 134,318,152\n",
      "Non-trainable params: 24,832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "vgg_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4621 images belonging to 8 classes.\n",
      "Found 0 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 70\n",
    "\n",
    "data_folder = 'data/Flowers'\n",
    "flower_types = [\"Babi\", \"Calimerio\", \"Chrysanthemum\", \"Hydrangeas\", \"Lisianthus\", \"Pingpong\", \"Rosy\", \"Tana\"]\n",
    "\n",
    "# Create empty lists to store image paths and corresponding labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop over the flower types and add image paths and labels to the lists\n",
    "for i, flower_type in enumerate(flower_types):\n",
    "    folder_path = os.path.join(data_folder, flower_type)\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.jpg'):\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            image_paths.append(image_path)\n",
    "            labels.append(i)\n",
    "\n",
    "# Shuffle the data\n",
    "data = list(zip(image_paths, labels))\n",
    "random.shuffle(data)\n",
    "image_paths, labels = zip(*data)\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_image_paths, val_image_paths, train_labels, val_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the data generators for the training and validation sets\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_folder,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    data_folder,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True), ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)]\n",
    "\n",
    "vgg_history = vgg_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vgg_history.history['accuracy'])\n",
    "plt.plot(vgg_history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(\n",
    "    X: tf.Tensor,\n",
    "    kernel_size: int,\n",
    "    filters: typing.List[int],\n",
    "    stage_no: int,\n",
    "    block_name: str,\n",
    "    is_conv_layer: bool = False,\n",
    "    stride: int = 2\n",
    ") -> tf.Tensor:\n",
    "\n",
    "    # names\n",
    "    conv_name_base = \"res\" + str(stage_no) + block_name + \"_branch\"\n",
    "    bn_name_base = \"bn\" + str(stage_no) + block_name + \"_branch\"\n",
    "\n",
    "    # filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # save the input value for shortcut.\n",
    "    X_shortcut = X\n",
    "\n",
    "    #  First component\n",
    "    # NOTE: if conv_layer, you need to do downsampling\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters = F1,\n",
    "        kernel_size = (1, 1),\n",
    "        strides = (stride, stride) if is_conv_layer else (1, 1),\n",
    "        padding = \"valid\",\n",
    "        name = conv_name_base + \"2a\",\n",
    "        kernel_initializer = \"glorot_uniform\",\n",
    "    )(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + \"2a\")(X)\n",
    "    X = tf.keras.layers.Activation(\"relu\")(X)\n",
    "\n",
    "    # Second component\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters = F2,\n",
    "        kernel_size = (kernel_size, kernel_size),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        name = conv_name_base + \"2b\",\n",
    "        kernel_initializer = \"glorot_uniform\",\n",
    "    )(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + \"2b\")(X)\n",
    "    X = tf.keras.layers.Activation(\"relu\")(X)\n",
    "\n",
    "    # Third component\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters = F3,\n",
    "        kernel_size = (1, 1),\n",
    "        strides = (1, 1),\n",
    "        padding = \"valid\",\n",
    "        name = conv_name_base + \"2c\",\n",
    "        kernel_initializer = \"glorot_uniform\",\n",
    "    )(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + \"2c\")(X)\n",
    "\n",
    "    if is_conv_layer:\n",
    "        X_shortcut = tf.keras.layers.Conv2D(\n",
    "            filters = F3,\n",
    "            kernel_size = (1, 1),\n",
    "            strides = (stride, stride),\n",
    "            padding = \"valid\",\n",
    "            name = conv_name_base + \"1\",\n",
    "            kernel_initializer = \"glorot_uniform\",\n",
    "        )(X_shortcut)\n",
    "        X_shortcut = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + \"1\")(X_shortcut)\n",
    "\n",
    "    # Shortcut value\n",
    "    X = tf.keras.layers.Add()([X, X_shortcut])\n",
    "    X = tf.keras.layers.Activation(\"relu\")(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet(name: str, layers: typing.List[int], input_shape: typing.Tuple[int] = (64, 64, 3), classes: int = 6) -> tf.keras.Model:\n",
    "    \n",
    "    # get layers (layer1 is always the same so no need to provide)\n",
    "    layer2, layer3, layer4, layer5 = layers\n",
    "\n",
    "    # convert input shape into tensor\n",
    "    X_input = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    # zero-padding\n",
    "    X = tf.keras.layers.ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # conv1\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (7, 7),\n",
    "        strides = (2, 2),\n",
    "        name = \"conv1\",\n",
    "        kernel_initializer = \"glorot_uniform\",\n",
    "    )(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = \"bn_conv1\")(X)\n",
    "    X = tf.keras.layers.Activation(\"relu\")(X)\n",
    "    X = tf.keras.layers.MaxPooling2D((3, 3), strides = (2, 2))(X)\n",
    "\n",
    "    # conv2_x\n",
    "    X = make_layer(X, layers = layer2, kernel_size = 3, filters = [64, 64, 256], stride = 1, stage_no = 2)\n",
    "\n",
    "    # conv3_x\n",
    "    X = make_layer(X, layers = layer3, kernel_size = 3, filters = [128, 128, 512], stride = 2, stage_no = 3)\n",
    "\n",
    "    # conv4_x\n",
    "    X = make_layer(X, layers = layer4, kernel_size = 3, filters = [256, 256, 1024], stride = 2, stage_no = 4)\n",
    "\n",
    "    # conv5_x\n",
    "    X = make_layer(X, layers = layer5, kernel_size = 3, filters = [512, 512, 2048], stride = 1, stage_no = 5)\n",
    "\n",
    "    # average pooling\n",
    "    X = tf.keras.layers.AveragePooling2D((2, 2), name = \"avg_pool\")(X)\n",
    "\n",
    "    # output layer\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    X = tf.keras.layers.Dense(\n",
    "        classes,\n",
    "        activation = \"softmax\",\n",
    "        name=\"fc\" + str(classes),\n",
    "        kernel_initializer = \"glorot_uniform\"\n",
    "    )(X)\n",
    "\n",
    "    model = tf.keras.Model(inputs = X_input, outputs = X, name = name)\n",
    "    return model\n",
    "\n",
    "def make_layer(X: tf.Tensor, layers: int, kernel_size: int, filters: typing.List[int], stride: int, stage_no: int) -> tf.Tensor:\n",
    "\n",
    "    # create convolution block\n",
    "    X = block(\n",
    "        X,\n",
    "        kernel_size = kernel_size,\n",
    "        filters = filters,\n",
    "        stage_no = stage_no,\n",
    "        block_name = \"a\",\n",
    "        is_conv_layer = True,\n",
    "        stride = stride\n",
    "    )\n",
    "\n",
    "    # create identity block\n",
    "    block_name_ordinal = ord(\"b\")\n",
    "    for _ in range(layers - 1):\n",
    "        X = block(\n",
    "            X,\n",
    "            kernel_size = kernel_size,\n",
    "            filters =  filters,\n",
    "            stage_no = stage_no,\n",
    "            block_name = chr(block_name_ordinal)\n",
    "        )\n",
    "        block_name_ordinal += 1\n",
    "\n",
    "    return X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
