{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGGNet(\n",
    "    name: str,\n",
    "    architecture: typing.List[ typing.Union[int, str] ],\n",
    "    input_shape: typing.Tuple[int],\n",
    "    classes: int = 1000\n",
    ") -> tf.keras.Model:\n",
    "    X_input = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    X = make_conv_layer(X_input, architecture)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    X = make_dense_layer(X, 4096)\n",
    "    X = make_dense_layer(X, 4096)\n",
    "\n",
    "    # classification layer\n",
    "    X = tf.keras.layers.Dense(units = classes, activation = \"softmax\")(X)\n",
    "\n",
    "    model = tf.keras.Model(inputs = X_input, outputs = X, name = name)\n",
    "    return model\n",
    "\n",
    "def make_conv_layer(\n",
    "    X: tf.Tensor,\n",
    "    architecture: typing.List[ typing.Union[int, str] ],\n",
    "    activation: str = 'relu'\n",
    ") -> tf.Tensor:\n",
    "\n",
    "    for output in architecture:\n",
    "\n",
    "        if type(output) == int:\n",
    "            out_channels = output\n",
    "\n",
    "            X = tf.keras.layers.Conv2D(\n",
    "                filters = out_channels,\n",
    "                kernel_size = (3, 3),\n",
    "                strides = (1, 1),\n",
    "                padding = \"same\"\n",
    "            )(X)\n",
    "            X = tf.keras.layers.BatchNormalization()(X)\n",
    "            X = tf.keras.layers.Activation(activation)(X)\n",
    "        else:\n",
    "            X = tf.keras.layers.MaxPooling2D(\n",
    "                pool_size = (2, 2),\n",
    "                strides = (2, 2)\n",
    "            )(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def make_dense_layer(X: tf.Tensor, output_units: int, dropout = 0.5, activation = 'relu') -> tf.Tensor:\n",
    "    X = tf.keras.layers.Dense(units = output_units)(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation(activation)(X)\n",
    "    X = tf.keras.layers.Dropout(dropout)(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_types = {\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "vgg_model = VGGNet(name = \"VGGNet16\", architecture = VGG_types[\"VGG16\"], input_shape=(224, 224, 3), classes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "vgg_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/Flowers'\n",
    "train_data_folder = 'data/train'\n",
    "validation_data_folder = 'data/validation'\n",
    "flower_types = [\"Babi\", \"Calimerio\", \"Chrysanthemum\", \"Hydrangeas\", \"Lisianthus\", \"Pingpong\", \"Rosy\", \"Tana\"]\n",
    "\n",
    "# Create empty lists to store image paths and corresponding labels\n",
    "train_image_paths = []\n",
    "train_labels = []\n",
    "val_image_paths = []\n",
    "val_labels = []\n",
    "\n",
    "# Loop over the flower types and add image paths and labels to the lists\n",
    "for i, flower_type in enumerate(flower_types):\n",
    "    folder_path = os.path.join(data_folder, flower_type)\n",
    "    files = os.listdir(folder_path)\n",
    "    random.shuffle(files)\n",
    "    split_index = int(0.8 * len(files))\n",
    "    train_files = files[:split_index]\n",
    "    val_files = files[split_index:]\n",
    "    \n",
    "    for file_name in train_files:\n",
    "        if file_name.endswith('.jpg'):\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            train_image_paths.append(image_path)\n",
    "            train_labels.append(i)\n",
    "            \n",
    "            os.makedirs(os.path.join(train_data_folder, flower_type), exist_ok=True)\n",
    "            shutil.copy(image_path, os.path.join(train_data_folder, flower_type, file_name))\n",
    "            \n",
    "    for file_name in val_files:\n",
    "        if file_name.endswith('.jpg'):\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            val_image_paths.append(image_path)\n",
    "            val_labels.append(i)\n",
    "            \n",
    "            os.makedirs(os.path.join(validation_data_folder, flower_type), exist_ok=True)\n",
    "            shutil.copy(image_path, os.path.join(validation_data_folder, flower_type, file_name))\n",
    "            \n",
    "# Define the data generators for the training and validation sets\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_folder,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_folder,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "epochs=70\n",
    "\n",
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True), ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)]\n",
    "\n",
    "vgg_history = vgg_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vgg_history.history['accuracy'])\n",
    "plt.plot(vgg_history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(\n",
    "    X: tf.Tensor,\n",
    "    kernel_size: int,\n",
    "    filters: typing.List[int],\n",
    "    stage_no: int,\n",
    "    block_name: str,\n",
    "    is_conv_layer: bool = False,\n",
    "    stride: int = 2\n",
    ") -> tf.Tensor:\n",
    "\n",
    "    # names\n",
    "    conv_name_base = \"res\" + str(stage_no) + block_name + \"_branch\"\n",
    "    bn_name_base = \"bn\" + str(stage_no) + block_name + \"_branch\"\n",
    "\n",
    "    # filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # save the input value for shortcut.\n",
    "    X_shortcut = X\n",
    "\n",
    "    #  First component\n",
    "    # NOTE: if conv_layer, you need to do downsampling\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters = F1,\n",
    "        kernel_size = (1, 1),\n",
    "        strides = (stride, stride) if is_conv_layer else (1, 1),\n",
    "        padding = \"valid\",\n",
    "        name = conv_name_base + \"2a\",\n",
    "        kernel_initializer = \"glorot_uniform\",\n",
    "    )(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + \"2a\")(X)\n",
    "    X = tf.keras.layers.Activation(\"relu\")(X)\n",
    "\n",
    "    # Second component\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters = F2,\n",
    "        kernel_size = (kernel_size, kernel_size),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        name = conv_name_base + \"2b\",\n",
    "        kernel_initializer = \"glorot_uniform\",\n",
    "    )(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + \"2b\")(X)\n",
    "    X = tf.keras.layers.Activation(\"relu\")(X)\n",
    "\n",
    "    # Third component\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters = F3,\n",
    "        kernel_size = (1, 1),\n",
    "        strides = (1, 1),\n",
    "        padding = \"valid\",\n",
    "        name = conv_name_base + \"2c\",\n",
    "        kernel_initializer = \"glorot_uniform\",\n",
    "    )(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + \"2c\")(X)\n",
    "\n",
    "    if is_conv_layer:\n",
    "        X_shortcut = tf.keras.layers.Conv2D(\n",
    "            filters = F3,\n",
    "            kernel_size = (1, 1),\n",
    "            strides = (stride, stride),\n",
    "            padding = \"valid\",\n",
    "            name = conv_name_base + \"1\",\n",
    "            kernel_initializer = \"glorot_uniform\",\n",
    "        )(X_shortcut)\n",
    "        X_shortcut = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + \"1\")(X_shortcut)\n",
    "\n",
    "    # Shortcut value\n",
    "    X = tf.keras.layers.Add()([X, X_shortcut])\n",
    "    X = tf.keras.layers.Activation(\"relu\")(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet(name: str, layers: typing.List[int], input_shape: typing.Tuple[int] = (64, 64, 3), classes: int = 6) -> tf.keras.Model:\n",
    "    \n",
    "    # get layers (layer1 is always the same so no need to provide)\n",
    "    layer2, layer3, layer4, layer5 = layers\n",
    "\n",
    "    # convert input shape into tensor\n",
    "    X_input = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    # zero-padding\n",
    "    X = tf.keras.layers.ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # conv1\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (7, 7),\n",
    "        strides = (2, 2),\n",
    "        name = \"conv1\",\n",
    "        kernel_initializer = \"glorot_uniform\",\n",
    "    )(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = \"bn_conv1\")(X)\n",
    "    X = tf.keras.layers.Activation(\"relu\")(X)\n",
    "    X = tf.keras.layers.MaxPooling2D((3, 3), strides = (2, 2))(X)\n",
    "\n",
    "    # conv2_x\n",
    "    X = make_layer(X, layers = layer2, kernel_size = 3, filters = [64, 64, 256], stride = 1, stage_no = 2)\n",
    "\n",
    "    # conv3_x\n",
    "    X = make_layer(X, layers = layer3, kernel_size = 3, filters = [128, 128, 512], stride = 2, stage_no = 3)\n",
    "\n",
    "    # conv4_x\n",
    "    X = make_layer(X, layers = layer4, kernel_size = 3, filters = [256, 256, 1024], stride = 2, stage_no = 4)\n",
    "\n",
    "    # conv5_x\n",
    "    X = make_layer(X, layers = layer5, kernel_size = 3, filters = [512, 512, 2048], stride = 1, stage_no = 5)\n",
    "\n",
    "    # average pooling\n",
    "    X = tf.keras.layers.AveragePooling2D((2, 2), name = \"avg_pool\")(X)\n",
    "\n",
    "    # output layer\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    X = tf.keras.layers.Dense(\n",
    "        classes,\n",
    "        activation = \"softmax\",\n",
    "        name=\"fc\" + str(classes),\n",
    "        kernel_initializer = \"glorot_uniform\"\n",
    "    )(X)\n",
    "\n",
    "    model = tf.keras.Model(inputs = X_input, outputs = X, name = name)\n",
    "    return model\n",
    "\n",
    "def make_layer(X: tf.Tensor, layers: int, kernel_size: int, filters: typing.List[int], stride: int, stage_no: int) -> tf.Tensor:\n",
    "\n",
    "    # create convolution block\n",
    "    X = block(\n",
    "        X,\n",
    "        kernel_size = kernel_size,\n",
    "        filters = filters,\n",
    "        stage_no = stage_no,\n",
    "        block_name = \"a\",\n",
    "        is_conv_layer = True,\n",
    "        stride = stride\n",
    "    )\n",
    "\n",
    "    # create identity block\n",
    "    block_name_ordinal = ord(\"b\")\n",
    "    for _ in range(layers - 1):\n",
    "        X = block(\n",
    "            X,\n",
    "            kernel_size = kernel_size,\n",
    "            filters =  filters,\n",
    "            stage_no = stage_no,\n",
    "            block_name = chr(block_name_ordinal)\n",
    "        )\n",
    "        block_name_ordinal += 1\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def recommend_similar_images(vgg_model, image_path, data_folder, flower_types, top_n=10):\n",
    "    # Load and preprocess the input image\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "\n",
    "    # Extract the feature vector of the input image\n",
    "    features = vgg_model.predict(x)\n",
    "\n",
    "    # Calculate cosine similarities between the input image and all the images in the dataset\n",
    "    similarities = []\n",
    "    for i, flower_type in enumerate(flower_types):\n",
    "        folder_path = os.path.join(data_folder, flower_type)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.jpg'):\n",
    "                image_path = os.path.join(folder_path, file_name)\n",
    "                img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "                x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "                features_i = vgg_model.predict(x)\n",
    "                similarity = cosine_similarity(features, features_i)\n",
    "                similarities.append((image_path, flower_type, similarity[0][0]))\n",
    "\n",
    "    # Sort the similarities in descending order and select the top_n images\n",
    "    similarities = sorted(similarities, key=lambda x: x[2], reverse=True)[:top_n]\n",
    "\n",
    "    # Display the input image, filename, and flower type\n",
    "    display(Image(filename=image_path))\n",
    "    print(\"Input Image: \", os.path.basename(image_path), flower_types[train_labels[image_paths.index(image_path)]])\n",
    "\n",
    "    # Display the top_n similar images with their filenames, flower types, and cosine similarity scores\n",
    "    for image_path, flower_type, similarity in similarities:\n",
    "        display(Image(filename=image_path))\n",
    "        print(os.path.basename(image_path), flower_type, similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_similar_images(vgg_model, 'data/Flowers/Babi/babi_1.jpg', 'data/Flowers', flower_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
